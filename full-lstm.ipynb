{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4891975,"sourceType":"datasetVersion","datasetId":2836725},{"sourceId":4892127,"sourceType":"datasetVersion","datasetId":2836828}],"dockerImageVersionId":30369,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"bCUHBNr1PPQO","execution":{"iopub.status.busy":"2023-01-24T15:55:02.837394Z","iopub.execute_input":"2023-01-24T15:55:02.837837Z","iopub.status.idle":"2023-01-24T15:55:02.852007Z","shell.execute_reply.started":"2023-01-24T15:55:02.837803Z","shell.execute_reply":"2023-01-24T15:55:02.850995Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/db-regio/regular_travel_test.csv\n/kaggle/input/db-regio/ts_split.py\n/kaggle/input/db-regio/regular_route_definitions.csv\n/kaggle/input/db-regio/regular_travel.csv\n/kaggle/input/db-regio/wetter2019.csv\n/kaggle/input/db-regio/bus_stops.csv\n/kaggle/input/db-regio/regular_travel_raw.csv\n/kaggle/input/db-regio/Task_description.html\n/kaggle/input/db-regio/wdw_queries.csv\n/kaggle/input/db-regio/on_demand_travel_raw.csv\n/kaggle/input/db-regio/on_demand_travel_test.csv\n/kaggle/input/db-regio/on_demand_travel.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Read the data and convert the problem to classification","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n\nregular_travel = pd.read_csv('//kaggle/input/db-regio/regular_travel.csv', parse_dates=['date'])\n\n# first we remove the dummy test set rows\nregular_travel_train = regular_travel.dropna(subset = ['Passengers'])\n#bining of the target \ny = np.digitize(regular_travel_train.Passengers, bins=(1, 2, 3))\nregular_travel_train[\"Passengers_bined\"] = y\nprint(regular_travel.shape)\n#merge thhe hole data\nregular_travel = regular_travel.merge(regular_travel_train[[\"date\", \"hour\", \"EZone\", \"Passengers_bined\"]], on=[\"date\", \"hour\", \"EZone\"], how=\"left\")\nprint(regular_travel.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"_jCkUrlsPPQc","outputId":"bc194cd0-af94-44e6-cd19-26bf1fdeea6f","execution":{"iopub.status.busy":"2023-01-24T15:55:06.761802Z","iopub.execute_input":"2023-01-24T15:55:06.762290Z","iopub.status.idle":"2023-01-24T15:55:08.309855Z","shell.execute_reply.started":"2023-01-24T15:55:06.762251Z","shell.execute_reply":"2023-01-24T15:55:08.307753Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  if sys.path[0] == \"\":\n","output_type":"stream"},{"name":"stdout","text":"(420000, 4)\n(420000, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"regular_travel_train.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b71Ue8GQAB3u","outputId":"27ad244f-2c6a-41ad-9992-6f64853e10a3","execution":{"iopub.status.busy":"2023-01-24T15:55:13.065119Z","iopub.execute_input":"2023-01-24T15:55:13.065624Z","iopub.status.idle":"2023-01-24T15:55:13.077943Z","shell.execute_reply.started":"2023-01-24T15:55:13.065579Z","shell.execute_reply":"2023-01-24T15:55:13.076666Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(310800, 5)"},"metadata":{}}]},{"cell_type":"code","source":"regular_travel_train.reset_index(inplace=True,drop=True)\nregular_travel_train","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:55:14.864642Z","iopub.execute_input":"2023-01-24T15:55:14.865797Z","iopub.status.idle":"2023-01-24T15:55:14.897445Z","shell.execute_reply.started":"2023-01-24T15:55:14.865754Z","shell.execute_reply":"2023-01-24T15:55:14.895892Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             date                                 EZone  hour  Passengers  \\\n0      2019-01-01      15964 - Salzweg, Außenstelle LRA     0         0.0   \n1      2019-01-01      15964 - Salzweg, Außenstelle LRA     1         0.0   \n2      2019-01-01      15964 - Salzweg, Außenstelle LRA     2         0.0   \n3      2019-01-01      15964 - Salzweg, Außenstelle LRA     3         0.0   \n4      2019-01-01      15964 - Salzweg, Außenstelle LRA     4         0.0   \n...           ...                                   ...   ...         ...   \n310795 2019-12-09  9750 - Passau, Reisebüro Niedermayer    19         0.0   \n310796 2019-12-09  9750 - Passau, Reisebüro Niedermayer    20         0.0   \n310797 2019-12-09  9750 - Passau, Reisebüro Niedermayer    21         0.0   \n310798 2019-12-09  9750 - Passau, Reisebüro Niedermayer    22         0.0   \n310799 2019-12-09  9750 - Passau, Reisebüro Niedermayer    23         0.0   \n\n        Passengers_bined  \n0                      0  \n1                      0  \n2                      0  \n3                      0  \n4                      0  \n...                  ...  \n310795                 0  \n310796                 0  \n310797                 0  \n310798                 0  \n310799                 0  \n\n[310800 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>EZone</th>\n      <th>hour</th>\n      <th>Passengers</th>\n      <th>Passengers_bined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-01</td>\n      <td>15964 - Salzweg, Außenstelle LRA</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-01</td>\n      <td>15964 - Salzweg, Außenstelle LRA</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-01</td>\n      <td>15964 - Salzweg, Außenstelle LRA</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-01</td>\n      <td>15964 - Salzweg, Außenstelle LRA</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-01</td>\n      <td>15964 - Salzweg, Außenstelle LRA</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>310795</th>\n      <td>2019-12-09</td>\n      <td>9750 - Passau, Reisebüro Niedermayer</td>\n      <td>19</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>310796</th>\n      <td>2019-12-09</td>\n      <td>9750 - Passau, Reisebüro Niedermayer</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>310797</th>\n      <td>2019-12-09</td>\n      <td>9750 - Passau, Reisebüro Niedermayer</td>\n      <td>21</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>310798</th>\n      <td>2019-12-09</td>\n      <td>9750 - Passau, Reisebüro Niedermayer</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>310799</th>\n      <td>2019-12-09</td>\n      <td>9750 - Passau, Reisebüro Niedermayer</td>\n      <td>23</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>310800 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Read test data\nregular_travel_test=pd.read_csv('/kaggle/input/db-regio/regular_travel_test.csv',parse_dates=['date'])\nregular_travel_test['Passengers_bined'] = np.digitize(regular_travel_test.Passengers, bins=(1, 2, 3))","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:55:17.593195Z","iopub.execute_input":"2023-01-24T15:55:17.594452Z","iopub.status.idle":"2023-01-24T15:55:17.745884Z","shell.execute_reply.started":"2023-01-24T15:55:17.594405Z","shell.execute_reply":"2023-01-24T15:55:17.744620Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Extract train and test data of each bus stop and put them in dictionaries\n#we will use the 'hour' feature and the passengers number in this notebook for the predection\nunique_ezones = regular_travel_train['EZone'].unique().tolist()\ndfs = {}\ntest_dfs = {}\nfor idx, col in enumerate(unique_ezones):\n    dfs[f\"df_{idx}\"] = pd.DataFrame(regular_travel_train[regular_travel_train['EZone'] == col][['Passengers_bined','hour']])\n    test_dfs[f\"test_df_{idx}\"] = pd.DataFrame(regular_travel_test[regular_travel_test['EZone'] == col][['Passengers_bined','hour']])\n# print(dfs)\n# df=regular_travel_train['Passengers_bined']\n# df=pd.DataFrame(df) ","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:55:19.721354Z","iopub.execute_input":"2023-01-24T15:55:19.721877Z","iopub.status.idle":"2023-01-24T15:55:21.298231Z","shell.execute_reply.started":"2023-01-24T15:55:19.721831Z","shell.execute_reply":"2023-01-24T15:55:21.296625Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#size(train_data(bus_stop))=62016\ndfs['df_1']","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:55:25.628960Z","iopub.execute_input":"2023-01-24T15:55:25.629404Z","iopub.status.idle":"2023-01-24T15:55:25.642575Z","shell.execute_reply.started":"2023-01-24T15:55:25.629371Z","shell.execute_reply":"2023-01-24T15:55:25.641129Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        Passengers_bined  hour\n24                     0     0\n25                     0     1\n26                     0     2\n27                     0     3\n28                     0     4\n...                  ...   ...\n309643                 1    19\n309644                 0    20\n309645                 0    21\n309646                 0    22\n309647                 0    23\n\n[6216 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Passengers_bined</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>309643</th>\n      <td>1</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>309644</th>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>309645</th>\n      <td>0</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>309646</th>\n      <td>0</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>309647</th>\n      <td>0</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n<p>6216 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#size(test_data(bus_stop))=2184\ntest_dfs[f\"test_df_{1}\"].shape","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:55:28.406480Z","iopub.execute_input":"2023-01-24T15:55:28.406894Z","iopub.status.idle":"2023-01-24T15:55:28.414662Z","shell.execute_reply.started":"2023-01-24T15:55:28.406861Z","shell.execute_reply":"2023-01-24T15:55:28.413418Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(2184, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Preparing data for LSTM**","metadata":{}},{"cell_type":"code","source":"#we will use the previous 24 hours to predict the number of passengers of the 25th hour\n#we will create 24 lags(series)for each 3 weeks of the training and 1 week of predictions for each bus stop\n#and then store the new train and test datasets after creting those lags\nnum_lags=24\nnew_df = {}\nnew_test_df = {}\nfor i in range(len(unique_ezones)):\n    df_total = None\n    df_test_total = None\n    for j in range(1, num_lags + 1):\n        df = dfs[f\"df_{i}\"]\n        df_test = test_dfs[f\"test_df_{i}\"]\n        df_year = None\n        df_test_year = None\n        for k in range(12):            \n            df_month = df.iloc[k*504:(k+1)*504, :]\n            df_month.insert(loc=2,column=f't-{j}',value=df_month.iloc[:,0].shift(periods=j))\n            df_month.insert(loc=2,column=f'hour-{j}',value=df_month.iloc[:,1].shift(periods=j))\n            if (k == 0):\n                df_year = df_month\n            else:\n                df_year = pd.concat([df_year, df_month], ignore_index=True, sort=False)\n            \n            \n            df_test_month = df_test.iloc[k*168:(k+1)*168, :]\n            df_test_month.insert(loc=2,column=f't-{j}',value=df_test_month.iloc[:,0].shift(periods=j))\n            df_test_month.insert(loc=2,column=f'hour-{j}',value=df_test_month.iloc[:,1].shift(periods=j))\n            if (k == 0):\n                df_test_year = df_test_month\n            else:\n                df_test_year = pd.concat([df_test_year, df_test_month], ignore_index=True, sort=False)\n                \n                \n        if (j == 1):\n            df_total = df_year\n            df_test_total = df_test_year\n            \n        else:\n            df_total = pd.concat([df_total, df_year[[f't-{j}',f'hour-{j}']]], axis=1)\n            df_test_total = pd.concat([df_test_total, df_test_year[[f't-{j}',f'hour-{j}']]], axis=1)\n        \n    new_df[f\"df_{i}\"] = df_total\n    new_test_df[f\"test_df_{i}\"] = df_test_total\n#         print(df_month.head())\n#             dfs[f\"df_{i}\"].iloc[k:k+504, :] = df_month\n            \n            \n#             df.iloc[k:k+504, :] = dfs[f\"df_{i}\"]\n#             dfs[f\"df_{i}\"].insert(loc=1,column=f't-{j}',value=dfs[f\"df_{i}\"].iloc[:,0].shift(periods=j))\n        \n#             dfs[f\"df_{i}\"].dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:55:30.708874Z","iopub.execute_input":"2023-01-24T15:55:30.709381Z","iopub.status.idle":"2023-01-24T15:56:19.615635Z","shell.execute_reply.started":"2023-01-24T15:55:30.709337Z","shell.execute_reply":"2023-01-24T15:56:19.614527Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Shape(test_df_busstop)=168*12 because we will use 12weeks for testing and 12*3 weeks for training\nnew_test_df[f\"test_df_{1}\"].shape","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:25.206254Z","iopub.execute_input":"2023-01-24T15:56:25.206770Z","iopub.status.idle":"2023-01-24T15:56:25.213767Z","shell.execute_reply.started":"2023-01-24T15:56:25.206723Z","shell.execute_reply":"2023-01-24T15:56:25.212759Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(2016, 50)"},"metadata":{}}]},{"cell_type":"code","source":"#drop Naan values created after the lags\nfor i in range(len(unique_ezones)):\n    new_df[f\"df_{i}\"].dropna(inplace=True)\n    new_test_df[f\"test_df_{i}\"].dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:27.238692Z","iopub.execute_input":"2023-01-24T15:56:27.239104Z","iopub.status.idle":"2023-01-24T15:56:27.939583Z","shell.execute_reply.started":"2023-01-24T15:56:27.239072Z","shell.execute_reply":"2023-01-24T15:56:27.938367Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#shape(train_df(bus_stop))=12*3*7*24-12*24=5760\nnew_df['df_0']","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:29.661184Z","iopub.execute_input":"2023-01-24T15:56:29.661644Z","iopub.status.idle":"2023-01-24T15:56:29.708577Z","shell.execute_reply.started":"2023-01-24T15:56:29.661609Z","shell.execute_reply":"2023-01-24T15:56:29.706911Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      Passengers_bined  hour  hour-1  t-1  t-2  hour-2  t-3  hour-3  t-4  \\\n24                   0     0    23.0  0.0  0.0    22.0  0.0    21.0  0.0   \n25                   0     1     0.0  0.0  0.0    23.0  0.0    22.0  0.0   \n26                   0     2     1.0  0.0  0.0     0.0  0.0    23.0  0.0   \n27                   0     3     2.0  0.0  0.0     1.0  0.0     0.0  0.0   \n28                   0     4     3.0  0.0  0.0     2.0  0.0     1.0  0.0   \n...                ...   ...     ...  ...  ...     ...  ...     ...  ...   \n6043                 0    19    18.0  0.0  0.0    17.0  0.0    16.0  0.0   \n6044                 1    20    19.0  0.0  0.0    18.0  0.0    17.0  0.0   \n6045                 0    21    20.0  1.0  0.0    19.0  0.0    18.0  0.0   \n6046                 0    22    21.0  0.0  1.0    20.0  0.0    19.0  0.0   \n6047                 0    23    22.0  0.0  0.0    21.0  1.0    20.0  0.0   \n\n      hour-4  ...  t-20  hour-20  t-21  hour-21  t-22  hour-22  t-23  hour-23  \\\n24      20.0  ...   0.0      4.0   0.0      3.0   0.0      2.0   0.0      1.0   \n25      21.0  ...   0.0      5.0   0.0      4.0   0.0      3.0   0.0      2.0   \n26      22.0  ...   0.0      6.0   0.0      5.0   0.0      4.0   0.0      3.0   \n27      23.0  ...   0.0      7.0   0.0      6.0   0.0      5.0   0.0      4.0   \n28       0.0  ...   0.0      8.0   0.0      7.0   0.0      6.0   0.0      5.0   \n...      ...  ...   ...      ...   ...      ...   ...      ...   ...      ...   \n6043    15.0  ...   0.0     23.0   0.0     22.0   0.0     21.0   0.0     20.0   \n6044    16.0  ...   0.0      0.0   0.0     23.0   0.0     22.0   0.0     21.0   \n6045    17.0  ...   0.0      1.0   0.0      0.0   0.0     23.0   0.0     22.0   \n6046    18.0  ...   0.0      2.0   0.0      1.0   0.0      0.0   0.0     23.0   \n6047    19.0  ...   0.0      3.0   0.0      2.0   0.0      1.0   0.0      0.0   \n\n      t-24  hour-24  \n24     0.0      0.0  \n25     0.0      1.0  \n26     0.0      2.0  \n27     0.0      3.0  \n28     0.0      4.0  \n...    ...      ...  \n6043   0.0     19.0  \n6044   0.0     20.0  \n6045   0.0     21.0  \n6046   0.0     22.0  \n6047   0.0     23.0  \n\n[5760 rows x 50 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Passengers_bined</th>\n      <th>hour</th>\n      <th>hour-1</th>\n      <th>t-1</th>\n      <th>t-2</th>\n      <th>hour-2</th>\n      <th>t-3</th>\n      <th>hour-3</th>\n      <th>t-4</th>\n      <th>hour-4</th>\n      <th>...</th>\n      <th>t-20</th>\n      <th>hour-20</th>\n      <th>t-21</th>\n      <th>hour-21</th>\n      <th>t-22</th>\n      <th>hour-22</th>\n      <th>t-23</th>\n      <th>hour-23</th>\n      <th>t-24</th>\n      <th>hour-24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>4</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6043</th>\n      <td>0</td>\n      <td>19</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>6044</th>\n      <td>1</td>\n      <td>20</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>6045</th>\n      <td>0</td>\n      <td>21</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>6046</th>\n      <td>0</td>\n      <td>22</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>6047</th>\n      <td>0</td>\n      <td>23</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5760 rows × 50 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**OnehotEncoding of the target**","metadata":{}},{"cell_type":"code","source":"classes = [0, 1, 2, 3]\nclasses","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:32.184534Z","iopub.execute_input":"2023-01-24T15:56:32.185506Z","iopub.status.idle":"2023-01-24T15:56:32.194219Z","shell.execute_reply.started":"2023-01-24T15:56:32.185449Z","shell.execute_reply":"2023-01-24T15:56:32.193320Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[0, 1, 2, 3]"},"metadata":{}}]},{"cell_type":"code","source":"for j in range(len(unique_ezones)):\n    for i in classes:\n        new_df[f\"df_{j}\"]['class_'+str(i)] = new_df[f\"df_{j}\"]['Passengers_bined'] == i\n        new_df[f\"df_{j}\"]['class_'+str(i)] = new_df[f\"df_{j}\"]['class_'+str(i)].astype(int)\n        \n        new_test_df[f\"test_df_{j}\"]['class_'+str(i)] = new_test_df[f\"test_df_{j}\"]['Passengers_bined'] == i\n        new_test_df[f\"test_df_{j}\"]['class_'+str(i)] = new_test_df[f\"test_df_{j}\"]['class_'+str(i)].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:34.080430Z","iopub.execute_input":"2023-01-24T15:56:34.080916Z","iopub.status.idle":"2023-01-24T15:56:34.463195Z","shell.execute_reply.started":"2023-01-24T15:56:34.080879Z","shell.execute_reply":"2023-01-24T15:56:34.462059Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#new_shape(5760x54)\nnew_df[\"df_49\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:37.015938Z","iopub.execute_input":"2023-01-24T15:56:37.016983Z","iopub.status.idle":"2023-01-24T15:56:37.059301Z","shell.execute_reply.started":"2023-01-24T15:56:37.016944Z","shell.execute_reply":"2023-01-24T15:56:37.057850Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"      Passengers_bined  hour  hour-1  t-1  t-2  hour-2  t-3  hour-3  t-4  \\\n24                   0     0    23.0  0.0  0.0    22.0  0.0    21.0  0.0   \n25                   0     1     0.0  0.0  0.0    23.0  0.0    22.0  0.0   \n26                   0     2     1.0  0.0  0.0     0.0  0.0    23.0  0.0   \n27                   0     3     2.0  0.0  0.0     1.0  0.0     0.0  0.0   \n28                   0     4     3.0  0.0  0.0     2.0  0.0     1.0  0.0   \n...                ...   ...     ...  ...  ...     ...  ...     ...  ...   \n6043                 2    19    18.0  3.0  3.0    17.0  0.0    16.0  3.0   \n6044                 0    20    19.0  2.0  3.0    18.0  3.0    17.0  0.0   \n6045                 0    21    20.0  0.0  2.0    19.0  3.0    18.0  3.0   \n6046                 0    22    21.0  0.0  0.0    20.0  2.0    19.0  3.0   \n6047                 0    23    22.0  0.0  0.0    21.0  0.0    20.0  2.0   \n\n      hour-4  ...  t-22  hour-22  t-23  hour-23  t-24  hour-24  class_0  \\\n24      20.0  ...   0.0      2.0   0.0      1.0   0.0      0.0        1   \n25      21.0  ...   0.0      3.0   0.0      2.0   0.0      1.0        1   \n26      22.0  ...   0.0      4.0   0.0      3.0   0.0      2.0        1   \n27      23.0  ...   0.0      5.0   0.0      4.0   0.0      3.0        1   \n28       0.0  ...   0.0      6.0   0.0      5.0   0.0      4.0        1   \n...      ...  ...   ...      ...   ...      ...   ...      ...      ...   \n6043    15.0  ...   0.0     21.0   0.0     20.0   0.0     19.0        0   \n6044    16.0  ...   0.0     22.0   0.0     21.0   0.0     20.0        1   \n6045    17.0  ...   0.0     23.0   0.0     22.0   0.0     21.0        1   \n6046    18.0  ...   0.0      0.0   0.0     23.0   0.0     22.0        1   \n6047    19.0  ...   0.0      1.0   0.0      0.0   0.0     23.0        1   \n\n      class_1  class_2  class_3  \n24          0        0        0  \n25          0        0        0  \n26          0        0        0  \n27          0        0        0  \n28          0        0        0  \n...       ...      ...      ...  \n6043        0        1        0  \n6044        0        0        0  \n6045        0        0        0  \n6046        0        0        0  \n6047        0        0        0  \n\n[5760 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Passengers_bined</th>\n      <th>hour</th>\n      <th>hour-1</th>\n      <th>t-1</th>\n      <th>t-2</th>\n      <th>hour-2</th>\n      <th>t-3</th>\n      <th>hour-3</th>\n      <th>t-4</th>\n      <th>hour-4</th>\n      <th>...</th>\n      <th>t-22</th>\n      <th>hour-22</th>\n      <th>t-23</th>\n      <th>hour-23</th>\n      <th>t-24</th>\n      <th>hour-24</th>\n      <th>class_0</th>\n      <th>class_1</th>\n      <th>class_2</th>\n      <th>class_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>4</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6043</th>\n      <td>2</td>\n      <td>19</td>\n      <td>18.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6044</th>\n      <td>0</td>\n      <td>20</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>18.0</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6045</th>\n      <td>0</td>\n      <td>21</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>18.0</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6046</th>\n      <td>0</td>\n      <td>22</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6047</th>\n      <td>0</td>\n      <td>23</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>20.0</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5760 rows × 54 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#extract the target from the train and test datasets\ny_trains = {}\ny_tests = {}\nfor j in range(len(unique_ezones)):\n    y_trains[f'y_train_{j}'] = new_df[f\"df_{j}\"][['class_0','class_1','class_2','class_3']].to_numpy()\n    y_tests[f'y_test_{j}'] = new_test_df[f\"test_df_{j}\"][['class_0','class_1','class_2','class_3']].to_numpy()\n #convert the columns to int type   \n    for feature in new_df[f\"df_{j}\"].columns: \n        new_df[f\"df_{j}\"][feature] = new_df[f\"df_{j}\"][feature].astype(int)\n        new_test_df[f\"test_df_{j}\"][feature] = new_test_df[f\"test_df_{j}\"][feature].astype(int)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:39.803622Z","iopub.execute_input":"2023-01-24T15:56:39.804244Z","iopub.status.idle":"2023-01-24T15:56:42.546513Z","shell.execute_reply.started":"2023-01-24T15:56:39.804203Z","shell.execute_reply":"2023-01-24T15:56:42.545340Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"new_df[\"df_49\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:44.250857Z","iopub.execute_input":"2023-01-24T15:56:44.251363Z","iopub.status.idle":"2023-01-24T15:56:44.281626Z","shell.execute_reply.started":"2023-01-24T15:56:44.251321Z","shell.execute_reply":"2023-01-24T15:56:44.280188Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"      Passengers_bined  hour  hour-1  t-1  t-2  hour-2  t-3  hour-3  t-4  \\\n24                   0     0      23    0    0      22    0      21    0   \n25                   0     1       0    0    0      23    0      22    0   \n26                   0     2       1    0    0       0    0      23    0   \n27                   0     3       2    0    0       1    0       0    0   \n28                   0     4       3    0    0       2    0       1    0   \n...                ...   ...     ...  ...  ...     ...  ...     ...  ...   \n6043                 2    19      18    3    3      17    0      16    3   \n6044                 0    20      19    2    3      18    3      17    0   \n6045                 0    21      20    0    2      19    3      18    3   \n6046                 0    22      21    0    0      20    2      19    3   \n6047                 0    23      22    0    0      21    0      20    2   \n\n      hour-4  ...  t-22  hour-22  t-23  hour-23  t-24  hour-24  class_0  \\\n24        20  ...     0        2     0        1     0        0        1   \n25        21  ...     0        3     0        2     0        1        1   \n26        22  ...     0        4     0        3     0        2        1   \n27        23  ...     0        5     0        4     0        3        1   \n28         0  ...     0        6     0        5     0        4        1   \n...      ...  ...   ...      ...   ...      ...   ...      ...      ...   \n6043      15  ...     0       21     0       20     0       19        0   \n6044      16  ...     0       22     0       21     0       20        1   \n6045      17  ...     0       23     0       22     0       21        1   \n6046      18  ...     0        0     0       23     0       22        1   \n6047      19  ...     0        1     0        0     0       23        1   \n\n      class_1  class_2  class_3  \n24          0        0        0  \n25          0        0        0  \n26          0        0        0  \n27          0        0        0  \n28          0        0        0  \n...       ...      ...      ...  \n6043        0        1        0  \n6044        0        0        0  \n6045        0        0        0  \n6046        0        0        0  \n6047        0        0        0  \n\n[5760 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Passengers_bined</th>\n      <th>hour</th>\n      <th>hour-1</th>\n      <th>t-1</th>\n      <th>t-2</th>\n      <th>hour-2</th>\n      <th>t-3</th>\n      <th>hour-3</th>\n      <th>t-4</th>\n      <th>hour-4</th>\n      <th>...</th>\n      <th>t-22</th>\n      <th>hour-22</th>\n      <th>t-23</th>\n      <th>hour-23</th>\n      <th>t-24</th>\n      <th>hour-24</th>\n      <th>class_0</th>\n      <th>class_1</th>\n      <th>class_2</th>\n      <th>class_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>20</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>21</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>22</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6043</th>\n      <td>2</td>\n      <td>19</td>\n      <td>18</td>\n      <td>3</td>\n      <td>3</td>\n      <td>17</td>\n      <td>0</td>\n      <td>16</td>\n      <td>3</td>\n      <td>15</td>\n      <td>...</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6044</th>\n      <td>0</td>\n      <td>20</td>\n      <td>19</td>\n      <td>2</td>\n      <td>3</td>\n      <td>18</td>\n      <td>3</td>\n      <td>17</td>\n      <td>0</td>\n      <td>16</td>\n      <td>...</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>20</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6045</th>\n      <td>0</td>\n      <td>21</td>\n      <td>20</td>\n      <td>0</td>\n      <td>2</td>\n      <td>19</td>\n      <td>3</td>\n      <td>18</td>\n      <td>3</td>\n      <td>17</td>\n      <td>...</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>21</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6046</th>\n      <td>0</td>\n      <td>22</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>2</td>\n      <td>19</td>\n      <td>3</td>\n      <td>18</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6047</th>\n      <td>0</td>\n      <td>23</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>20</td>\n      <td>2</td>\n      <td>19</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5760 rows × 54 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:46.476857Z","iopub.execute_input":"2023-01-24T15:56:46.478395Z","iopub.status.idle":"2023-01-24T15:56:46.484786Z","shell.execute_reply.started":"2023-01-24T15:56:46.478324Z","shell.execute_reply":"2023-01-24T15:56:46.483466Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Prepare the training and testing data for LSTM to be 3D dimentional(n_samples,n_time_steps,n_features)\n#Scale the data to prevent overfitting\nx_trains = {}\nx_tests = {}\nfor j in range(len(unique_ezones)):\n    x_trains[f'x_train_{j}'] = new_df[f\"df_{j}\"].drop(columns=['Passengers_bined', 'class_0', 'class_1', 'class_2', 'class_3']).to_numpy()\n#     x_trains[f'x_train_{j}'] = x_trains[f'x_train_{j}'].reshape(x_trains[f'x_train_{j}'].shape[0], x_trains[f'x_train_{j}'].shape[1],1)\n    \n    \n    hours_columns = new_df[f\"df_{j}\"][[\"hour-1\", \"hour-2\", \"hour-3\", \"hour-4\", \"hour-5\", \"hour-6\", \"hour-7\",\n                                \"hour-8\", \"hour-9\", \"hour-10\", \"hour-11\", \"hour-12\", \"hour-13\",\n                                \"hour-14\", \"hour-15\", \"hour-16\", \"hour-17\", \"hour-18\", \"hour-19\",\n                                \"hour-20\", \"hour-21\", \"hour-22\", \"hour-23\", \"hour-24\"]].to_numpy()\n    scaler1=MinMaxScaler()\n    hours_columns=scaler1.fit_transform(hours_columns)\n    passengers_columns = new_df[f\"df_{j}\"][[\"t-1\", \"t-2\", \"t-3\", \"t-4\", \"t-5\", \"t-6\", \"t-7\",\n                                    \"t-8\", \"t-9\", \"t-10\", \"t-11\", \"t-12\", \"t-13\",\n                                    \"t-14\", \"t-15\", \"t-16\", \"t-17\", \"t-18\", \"t-19\",\n                                    \"t-20\", \"t-21\", \"t-22\", \"t-23\", \"t-24\"]].to_numpy()\n    scaler2=MinMaxScaler()\n    passengers_columns=scaler2.fit_transform(passengers_columns)\n    x_trains[f'x_train_{j}'] = np.stack([hours_columns, passengers_columns], axis=2)\n    \n    \n    \n    x_tests[f'x_test_{j}'] = new_test_df[f\"test_df_{j}\"].drop(columns=['Passengers_bined', 'class_0', 'class_1', 'class_2', 'class_3']).to_numpy()\n    hours_columns_test = new_test_df[f\"test_df_{j}\"][[\"hour-1\", \"hour-2\", \"hour-3\", \"hour-4\", \"hour-5\", \"hour-6\", \"hour-7\",\n                                \"hour-8\", \"hour-9\", \"hour-10\", \"hour-11\", \"hour-12\", \"hour-13\",\n                                \"hour-14\", \"hour-15\", \"hour-16\", \"hour-17\", \"hour-18\", \"hour-19\",\n                                \"hour-20\", \"hour-21\", \"hour-22\", \"hour-23\", \"hour-24\"]].to_numpy()\n    hours_columns_test=scaler1.fit_transform(hours_columns_test)\n    passengers_columns_test = new_test_df[f\"test_df_{j}\"][[\"t-1\", \"t-2\", \"t-3\", \"t-4\", \"t-5\", \"t-6\", \"t-7\",\n                                    \"t-8\", \"t-9\", \"t-10\", \"t-11\", \"t-12\", \"t-13\",\n                                    \"t-14\", \"t-15\", \"t-16\", \"t-17\", \"t-18\", \"t-19\",\n                                    \"t-20\", \"t-21\", \"t-22\", \"t-23\", \"t-24\"]].to_numpy()\n    passengers_columns_test=scaler2.fit_transform(passengers_columns_test)\n    x_tests[f'x_test_{j}'] = np.stack([hours_columns_test, passengers_columns_test], axis=2)\n    \n    \n    \n#     x_tests[f'x_test_{j}'] = x_tests[f'x_test_{j}'].reshape(x_tests[f'x_test_{j}'].shape[0], x_tests[f'x_test_{j}'].shape[1],1)","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:50.813711Z","iopub.execute_input":"2023-01-24T15:56:50.814198Z","iopub.status.idle":"2023-01-24T15:56:51.628250Z","shell.execute_reply.started":"2023-01-24T15:56:50.814160Z","shell.execute_reply":"2023-01-24T15:56:51.626998Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#shape=(n_samples,n_time_steps,n_features)=(5760,24,2)\nx_trains[f'x_train_{49}'].shape","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:55.610210Z","iopub.execute_input":"2023-01-24T15:56:55.610592Z","iopub.status.idle":"2023-01-24T15:56:55.618143Z","shell.execute_reply.started":"2023-01-24T15:56:55.610561Z","shell.execute_reply":"2023-01-24T15:56:55.616887Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(5760, 24, 2)"},"metadata":{}}]},{"cell_type":"code","source":"y_trains[\"y_train_0\"].shape","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:57.072704Z","iopub.execute_input":"2023-01-24T15:56:57.073408Z","iopub.status.idle":"2023-01-24T15:56:57.082380Z","shell.execute_reply.started":"2023-01-24T15:56:57.073356Z","shell.execute_reply":"2023-01-24T15:56:57.081438Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(5760, 4)"},"metadata":{}}]},{"cell_type":"code","source":"from keras.models import Sequential,Functional\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Dense\nfrom keras import metrics\nimport keras\nimport sklearn.metrics\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:56:59.301422Z","iopub.execute_input":"2023-01-24T15:56:59.301879Z","iopub.status.idle":"2023-01-24T15:57:06.444806Z","shell.execute_reply.started":"2023-01-24T15:56:59.301845Z","shell.execute_reply":"2023-01-24T15:57:06.443480Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"optimizer=Adam(learning_rate=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:57:06.447115Z","iopub.execute_input":"2023-01-24T15:57:06.447863Z","iopub.status.idle":"2023-01-24T15:57:06.462257Z","shell.execute_reply.started":"2023-01-24T15:57:06.447827Z","shell.execute_reply":"2023-01-24T15:57:06.460764Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Example: training LSTM on the first 3 weeks for one bus stop**","metadata":{}},{"cell_type":"code","source":"y=y_trains[f'y_train_{49}'][0:480]\nX=x_trains[f'x_train_{49}'][0:480]\ny_test=y_tests[f'y_test_{49}'][0:144]\nx_test=x_tests[f'x_test_{49}'][0:144]","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:57:09.710622Z","iopub.execute_input":"2023-01-24T15:57:09.711144Z","iopub.status.idle":"2023-01-24T15:57:09.718389Z","shell.execute_reply.started":"2023-01-24T15:57:09.711106Z","shell.execute_reply":"2023-01-24T15:57:09.716593Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#Ajust class_weights using training data\ndecoded_y=np.argmax(y,axis=1)\nclass_0=np.count_nonzero(decoded_y==0)\nclass_1=np.count_nonzero(decoded_y==1)\nclass_2=np.count_nonzero(decoded_y==2)\nclass_3=np.count_nonzero(decoded_y==3)\nS=class_0+class_1+class_2+class_3\nclass_weights={0:S/(class_0*4),1:S/(class_1*4),2:S/(class_2*4),3:S/(class_3*4)}\nprint(class_weights)","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:57:13.523959Z","iopub.execute_input":"2023-01-24T15:57:13.525546Z","iopub.status.idle":"2023-01-24T15:57:13.536437Z","shell.execute_reply.started":"2023-01-24T15:57:13.525480Z","shell.execute_reply":"2023-01-24T15:57:13.535103Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{0: 0.3333333333333333, 1: 2.2641509433962264, 2: 4.137931034482759, 3: 3.1578947368421053}\n","output_type":"stream"}]},{"cell_type":"code","source":"estimator=Sequential()\nestimator.add(LSTM(units=1,activation='relu',input_shape=(24,2)))\n#estimator.add(Dropout(0.2))\n#estimator.add(LSTM(4, activation='relu',,return_sequences=True))\n#estimator.add(Dropout(0.1))\n#estimator.add(LSTM(10, activation='relu'))\n#estimator.add(Dropout(0.2))\nestimator.add(Dense(units=4,activation='softmax'))\nestimator.compile(loss='categorical_crossentropy',optimizer=optimizer)\nhistory=estimator.fit(X,y,batch_size=10,epochs=5,validation_split=0.3)\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()\n#pred = model.predict(x_tests[f'x_test_{49}'][0:144])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:57:15.637434Z","iopub.execute_input":"2023-01-24T15:57:15.637895Z","iopub.status.idle":"2023-01-24T15:57:19.896163Z","shell.execute_reply.started":"2023-01-24T15:57:15.637860Z","shell.execute_reply":"2023-01-24T15:57:19.895150Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"2023-01-24 15:57:15.671670: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n2023-01-24 15:57:15.922295: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n34/34 [==============================] - 2s 20ms/step - loss: 1.3716 - val_loss: 1.3520\nEpoch 2/5\n34/34 [==============================] - 0s 10ms/step - loss: 1.3423 - val_loss: 1.3197\nEpoch 3/5\n34/34 [==============================] - 0s 10ms/step - loss: 1.3145 - val_loss: 1.2885\nEpoch 4/5\n34/34 [==============================] - 0s 10ms/step - loss: 1.2885 - val_loss: 1.2583\nEpoch 5/5\n34/34 [==============================] - 0s 10ms/step - loss: 1.2631 - val_loss: 1.2298\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# Create a model for each bus stop ","metadata":{}},{"cell_type":"code","source":"#use incremental training to improve the model performance by using \n#the training data of the previous months to retrain the model\nstations_f1_scores={}\npredictions = pd.DataFrame()\nfor j in range(len(unique_ezones)):\n    model=Sequential()\n    model.add(LSTM(units=1,activation='relu',input_shape=(24,2)))\n    model.add(Dense(units=4,activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer=optimizer)\n    f1_sc=0\n    for k in range(12):\n        model.fit(x_trains[f'x_train_{j}'][0:(k+1)*480],y_trains[f'y_train_{j}'][0:(k+1)*480],batch_size=10,epochs=10,validation_split=0.3)\n        pred = model.predict(x_tests[f'x_test_{j}'][k*144:(k+1)*144,:,:])\n        decoded_pred=np.argmax(pred,axis=1)\n        y_true=np.argmax(y_tests[f'y_test_{j}'][k*144:(k+1)*144,:],axis=1)\n        f1_sc=f1_sc+sklearn.metrics.f1_score(decoded_pred,y_true,average='micro')\n        print(sklearn.metrics.f1_score(decoded_pred,y_true,average='micro'))\n    avg_f1_score=f1_sc/12\n    stations_f1_scores[j]=avg_f1_score\n    model.save(f'model_{j}.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-24T15:57:26.206117Z","iopub.execute_input":"2023-01-24T15:57:26.206644Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n34/34 [==============================] - 2s 19ms/step - loss: 1.4494 - val_loss: 1.3192\nEpoch 2/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.2756 - val_loss: 1.2444\nEpoch 3/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.2077 - val_loss: 1.1898\nEpoch 4/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.1549 - val_loss: 1.1425\nEpoch 5/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1091 - val_loss: 1.1020\nEpoch 6/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.0687 - val_loss: 1.0658\nEpoch 7/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.0322 - val_loss: 1.0334\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9994 - val_loss: 1.0028\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9689 - val_loss: 0.9757\nEpoch 10/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9410 - val_loss: 0.9508\n0.7986111111111112\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9005 - val_loss: 0.8455\nEpoch 2/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8558 - val_loss: 0.8009\nEpoch 3/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.8170 - val_loss: 0.7631\nEpoch 4/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7832 - val_loss: 0.7280\nEpoch 5/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7535 - val_loss: 0.6984\nEpoch 6/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.7278 - val_loss: 0.6716\nEpoch 7/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7053 - val_loss: 0.6486\nEpoch 8/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.6859 - val_loss: 0.6276\nEpoch 9/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.6691 - val_loss: 0.6097\nEpoch 10/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.6544 - val_loss: 0.5945\n0.7916666666666666\nEpoch 1/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.6315 - val_loss: 0.5517\nEpoch 2/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.6148 - val_loss: 0.5333\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.6009 - val_loss: 0.5174\nEpoch 4/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5895 - val_loss: 0.5041\nEpoch 5/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.5800 - val_loss: 0.4924\nEpoch 6/10\n101/101 [==============================] - 1s 12ms/step - loss: 0.5721 - val_loss: 0.4826\nEpoch 7/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.5656 - val_loss: 0.4744\nEpoch 8/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.5602 - val_loss: 0.4667\nEpoch 9/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5555 - val_loss: 0.4609\nEpoch 10/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5517 - val_loss: 0.4554\n0.8125\nEpoch 1/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.5124 - val_loss: 0.5588\nEpoch 2/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.5075 - val_loss: 0.5553\nEpoch 3/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.5036 - val_loss: 0.5524\nEpoch 4/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.5006 - val_loss: 0.5502\nEpoch 5/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.4980 - val_loss: 0.5483\nEpoch 6/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.4961 - val_loss: 0.5469\nEpoch 7/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.4944 - val_loss: 0.5456\nEpoch 8/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.4930 - val_loss: 0.5444\nEpoch 9/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.4918 - val_loss: 0.5434\nEpoch 10/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.4908 - val_loss: 0.5426\n0.875\nEpoch 1/10\n168/168 [==============================] - 2s 9ms/step - loss: 0.5168 - val_loss: 0.4438\nEpoch 2/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.5154 - val_loss: 0.4432\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5141 - val_loss: 0.4426\nEpoch 4/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5130 - val_loss: 0.4418\nEpoch 5/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.5123 - val_loss: 0.4414\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5116 - val_loss: 0.4409\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5113 - val_loss: 0.4411\nEpoch 8/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5108 - val_loss: 0.4403\nEpoch 9/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5104 - val_loss: 0.4406\nEpoch 10/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.5103 - val_loss: 0.4395\n0.8263888888888888\nEpoch 1/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5096 - val_loss: 0.4159\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5092 - val_loss: 0.4155\nEpoch 3/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5091 - val_loss: 0.4155\nEpoch 4/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5087 - val_loss: 0.4150\nEpoch 5/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5081 - val_loss: 0.4144\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5077 - val_loss: 0.4146\nEpoch 7/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.5070 - val_loss: 0.4147\nEpoch 8/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5061 - val_loss: 0.4125\nEpoch 9/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5060 - val_loss: 0.4123\nEpoch 10/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.5050 - val_loss: 0.4137\n0.8958333333333334\nEpoch 1/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4861 - val_loss: 0.4887\nEpoch 2/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4853 - val_loss: 0.4877\nEpoch 3/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.4834 - val_loss: 0.4872\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4815 - val_loss: 0.4851\nEpoch 5/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4799 - val_loss: 0.4836\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4769 - val_loss: 0.4798\nEpoch 7/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4750 - val_loss: 0.4779\nEpoch 8/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4715 - val_loss: 0.4741\nEpoch 9/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4686 - val_loss: 0.4731\nEpoch 10/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.4656 - val_loss: 0.4728\n0.9166666666666666\nEpoch 1/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.4600 - val_loss: 0.5140\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4562 - val_loss: 0.5070\nEpoch 3/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4531 - val_loss: 0.5041\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4501 - val_loss: 0.5018\nEpoch 5/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4477 - val_loss: 0.5001\nEpoch 6/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.4446 - val_loss: 0.4967\nEpoch 7/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4428 - val_loss: 0.4959\nEpoch 8/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.4397 - val_loss: 0.4942\nEpoch 9/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4380 - val_loss: 0.4915\nEpoch 10/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4355 - val_loss: 0.4911\n0.9583333333333334\nEpoch 1/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4302 - val_loss: 0.5157\nEpoch 2/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4294 - val_loss: 0.5103\nEpoch 3/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4265 - val_loss: 0.5143\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4264 - val_loss: 0.5102\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4253 - val_loss: 0.5058\nEpoch 6/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4245 - val_loss: 0.5047\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4224 - val_loss: 0.5046\nEpoch 8/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.4210 - val_loss: 0.5023\nEpoch 9/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4207 - val_loss: 0.5057\nEpoch 10/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4203 - val_loss: 0.5010\n0.9305555555555556\nEpoch 1/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.4276 - val_loss: 0.5302\nEpoch 2/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4269 - val_loss: 0.5291\nEpoch 3/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4252 - val_loss: 0.5277\nEpoch 4/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4258 - val_loss: 0.5269\nEpoch 5/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4252 - val_loss: 0.5342\nEpoch 6/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.4232 - val_loss: 0.5354\nEpoch 7/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4235 - val_loss: 0.5244\nEpoch 8/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4235 - val_loss: 0.5257\nEpoch 9/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4217 - val_loss: 0.5282\nEpoch 10/10\n336/336 [==============================] - 3s 9ms/step - loss: 0.4219 - val_loss: 0.5216\n0.9305555555555556\nEpoch 1/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4349 - val_loss: 0.5153\nEpoch 2/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4342 - val_loss: 0.5145\nEpoch 3/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4338 - val_loss: 0.5204\nEpoch 4/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4332 - val_loss: 0.5146\nEpoch 5/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4318 - val_loss: 0.5126\nEpoch 6/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4320 - val_loss: 0.5136\nEpoch 7/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4331 - val_loss: 0.5115\nEpoch 8/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4312 - val_loss: 0.5129\nEpoch 9/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4311 - val_loss: 0.5105\nEpoch 10/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4315 - val_loss: 0.5126\n0.9166666666666666\nEpoch 1/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4318 - val_loss: 0.4449\nEpoch 2/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4318 - val_loss: 0.4442\nEpoch 3/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4314 - val_loss: 0.4445\nEpoch 4/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4306 - val_loss: 0.4432\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4304 - val_loss: 0.4437\nEpoch 6/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.4311 - val_loss: 0.4427\nEpoch 7/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4295 - val_loss: 0.4463\nEpoch 8/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4304 - val_loss: 0.4471\nEpoch 9/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4289 - val_loss: 0.4437\nEpoch 10/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4286 - val_loss: 0.4416\n0.9791666666666666\nEpoch 1/10\n34/34 [==============================] - 2s 20ms/step - loss: 1.3046 - val_loss: 1.2153\nEpoch 2/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1642 - val_loss: 1.0991\nEpoch 3/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.0639 - val_loss: 1.0089\nEpoch 4/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9941 - val_loss: 0.9523\nEpoch 5/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9472 - val_loss: 0.9150\nEpoch 6/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9131 - val_loss: 0.8864\nEpoch 7/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8870 - val_loss: 0.8638\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8653 - val_loss: 0.8447\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8489 - val_loss: 0.8298\nEpoch 10/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8349 - val_loss: 0.8173\n0.763888888888889\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8353 - val_loss: 0.8240\nEpoch 2/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.8208 - val_loss: 0.8133\nEpoch 3/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.8084 - val_loss: 0.8055\nEpoch 4/10\n68/68 [==============================] - 1s 11ms/step - loss: 0.7988 - val_loss: 0.7989\nEpoch 5/10\n68/68 [==============================] - 1s 11ms/step - loss: 0.7922 - val_loss: 0.7940\nEpoch 6/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7863 - val_loss: 0.7904\nEpoch 7/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7808 - val_loss: 0.7870\nEpoch 8/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7767 - val_loss: 0.7851\nEpoch 9/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.7739 - val_loss: 0.7825\nEpoch 10/10\n68/68 [==============================] - 1s 11ms/step - loss: 0.7708 - val_loss: 0.7808\n0.7013888888888888\nEpoch 1/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7660 - val_loss: 0.8154\nEpoch 2/10\n101/101 [==============================] - 1s 11ms/step - loss: 0.7634 - val_loss: 0.8140\nEpoch 3/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7605 - val_loss: 0.8127\nEpoch 4/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7587 - val_loss: 0.8126\nEpoch 5/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7572 - val_loss: 0.8113\nEpoch 6/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7549 - val_loss: 0.8108\nEpoch 7/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7536 - val_loss: 0.8095\nEpoch 8/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7521 - val_loss: 0.8095\nEpoch 9/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7512 - val_loss: 0.8085\nEpoch 10/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7499 - val_loss: 0.8084\n0.7291666666666665\nEpoch 1/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.7564 - val_loss: 0.7507\nEpoch 2/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7556 - val_loss: 0.7497\nEpoch 3/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7544 - val_loss: 0.7493\nEpoch 4/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7538 - val_loss: 0.7482\nEpoch 5/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7530 - val_loss: 0.7477\nEpoch 6/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7518 - val_loss: 0.7472\nEpoch 7/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.7509 - val_loss: 0.7469\nEpoch 8/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7506 - val_loss: 0.7464\nEpoch 9/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7494 - val_loss: 0.7459\nEpoch 10/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7487 - val_loss: 0.7458\n0.7430555555555556\nEpoch 1/10\n168/168 [==============================] - 2s 9ms/step - loss: 0.7377 - val_loss: 0.7921\nEpoch 2/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7370 - val_loss: 0.7923\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7361 - val_loss: 0.7920\nEpoch 4/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7356 - val_loss: 0.7919\nEpoch 5/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7352 - val_loss: 0.7919\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7350 - val_loss: 0.7918\nEpoch 7/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7340 - val_loss: 0.7919\nEpoch 8/10\n168/168 [==============================] - 1s 9ms/step - loss: 0.7336 - val_loss: 0.7919\nEpoch 9/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7329 - val_loss: 0.7921\nEpoch 10/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7325 - val_loss: 0.7917\n0.763888888888889\nEpoch 1/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7342 - val_loss: 0.8058\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7337 - val_loss: 0.8053\nEpoch 3/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7337 - val_loss: 0.8051\nEpoch 4/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7333 - val_loss: 0.8049\nEpoch 5/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7328 - val_loss: 0.8049\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7326 - val_loss: 0.8047\nEpoch 7/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7319 - val_loss: 0.8044\nEpoch 8/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.7316 - val_loss: 0.8042\nEpoch 9/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7311 - val_loss: 0.8043\nEpoch 10/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7311 - val_loss: 0.8040\n0.75\nEpoch 1/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7431 - val_loss: 0.7923\nEpoch 2/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7426 - val_loss: 0.7922\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7421 - val_loss: 0.7902\nEpoch 4/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.7417 - val_loss: 0.7903\nEpoch 5/10\n236/236 [==============================] - 3s 11ms/step - loss: 0.7415 - val_loss: 0.7895\nEpoch 6/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.7412 - val_loss: 0.7904\nEpoch 7/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7411 - val_loss: 0.7894\nEpoch 8/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.7403 - val_loss: 0.7889\nEpoch 9/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.7403 - val_loss: 0.7891\nEpoch 10/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7397 - val_loss: 0.7889\n0.75\nEpoch 1/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7483 - val_loss: 0.7327\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7475 - val_loss: 0.7327\nEpoch 3/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.7475 - val_loss: 0.7317\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7472 - val_loss: 0.7312\nEpoch 5/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7464 - val_loss: 0.7307\nEpoch 6/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7460 - val_loss: 0.7301\nEpoch 7/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7455 - val_loss: 0.7296\nEpoch 8/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.7453 - val_loss: 0.7291\nEpoch 9/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7445 - val_loss: 0.7285\nEpoch 10/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7439 - val_loss: 0.7280\n0.7430555555555556\nEpoch 1/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7487 - val_loss: 0.7466\nEpoch 2/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7471 - val_loss: 0.7459\nEpoch 3/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7465 - val_loss: 0.7451\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7464 - val_loss: 0.7446\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7456 - val_loss: 0.7439\nEpoch 6/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7447 - val_loss: 0.7437\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7440 - val_loss: 0.7433\nEpoch 8/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7437 - val_loss: 0.7425\nEpoch 9/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.7433 - val_loss: 0.7411\nEpoch 10/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.7424 - val_loss: 0.7404\n0.7361111111111113\nEpoch 1/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7425 - val_loss: 0.7229\nEpoch 2/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7416 - val_loss: 0.7220\nEpoch 3/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.7409 - val_loss: 0.7212\nEpoch 4/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7398 - val_loss: 0.7202\nEpoch 5/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.7390 - val_loss: 0.7188\nEpoch 6/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7379 - val_loss: 0.7171\nEpoch 7/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7366 - val_loss: 0.7157\nEpoch 8/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7355 - val_loss: 0.7149\nEpoch 9/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.7346 - val_loss: 0.7133\nEpoch 10/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.7330 - val_loss: 0.7121\n0.6944444444444444\nEpoch 1/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.7235 - val_loss: 0.7289\nEpoch 2/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.7213 - val_loss: 0.7290\nEpoch 3/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.7167 - val_loss: 0.7211\nEpoch 4/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.7113 - val_loss: 0.7163\nEpoch 5/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.7058 - val_loss: 0.7108\nEpoch 6/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.7004 - val_loss: 0.7052\nEpoch 7/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6941 - val_loss: 0.6983\nEpoch 8/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6869 - val_loss: 0.6931\nEpoch 9/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6808 - val_loss: 0.6844\nEpoch 10/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.6743 - val_loss: 0.6790\n0.7777777777777778\nEpoch 1/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.6727 - val_loss: 0.6689\nEpoch 2/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.6665 - val_loss: 0.6631\nEpoch 3/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6641 - val_loss: 0.6603\nEpoch 4/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6617 - val_loss: 0.6631\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6607 - val_loss: 0.6558\nEpoch 6/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6596 - val_loss: 0.6550\nEpoch 7/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6600 - val_loss: 0.6540\nEpoch 8/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6578 - val_loss: 0.6518\nEpoch 9/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.6587 - val_loss: 0.6516\nEpoch 10/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6583 - val_loss: 0.6509\n0.8055555555555556\nEpoch 1/10\n34/34 [==============================] - 2s 20ms/step - loss: 1.3495 - val_loss: 1.2992\nEpoch 2/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.2760 - val_loss: 1.2469\nEpoch 3/10\n34/34 [==============================] - 0s 9ms/step - loss: 1.2330 - val_loss: 1.2059\nEpoch 4/10\n34/34 [==============================] - 0s 9ms/step - loss: 1.1963 - val_loss: 1.1663\nEpoch 5/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1668 - val_loss: 1.1342\nEpoch 6/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1481 - val_loss: 1.1158\nEpoch 7/10\n34/34 [==============================] - 0s 9ms/step - loss: 1.1375 - val_loss: 1.1026\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1277 - val_loss: 1.0897\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1204 - val_loss: 1.0802\nEpoch 10/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1143 - val_loss: 1.0748\n0.5347222222222222\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 1.0705 - val_loss: 1.0100\nEpoch 2/10\n68/68 [==============================] - 1s 9ms/step - loss: 1.0567 - val_loss: 1.0001\nEpoch 3/10\n68/68 [==============================] - 1s 9ms/step - loss: 1.0448 - val_loss: 0.9923\nEpoch 4/10\n68/68 [==============================] - 1s 10ms/step - loss: 1.0352 - val_loss: 0.9852\nEpoch 5/10\n68/68 [==============================] - 1s 10ms/step - loss: 1.0279 - val_loss: 0.9819\nEpoch 6/10\n68/68 [==============================] - 1s 10ms/step - loss: 1.0210 - val_loss: 0.9772\nEpoch 7/10\n68/68 [==============================] - 1s 9ms/step - loss: 1.0154 - val_loss: 0.9730\nEpoch 8/10\n68/68 [==============================] - 1s 9ms/step - loss: 1.0111 - val_loss: 0.9696\nEpoch 9/10\n68/68 [==============================] - 1s 9ms/step - loss: 1.0065 - val_loss: 0.9675\nEpoch 10/10\n68/68 [==============================] - 1s 9ms/step - loss: 1.0029 - val_loss: 0.9649\n0.6527777777777778\nEpoch 1/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9837 - val_loss: 0.9399\nEpoch 2/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9798 - val_loss: 0.9374\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9763 - val_loss: 0.9359\nEpoch 4/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9729 - val_loss: 0.9351\nEpoch 5/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9707 - val_loss: 0.9344\nEpoch 6/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9685 - val_loss: 0.9326\nEpoch 7/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9666 - val_loss: 0.9322\nEpoch 8/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9643 - val_loss: 0.9301\nEpoch 9/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.9629 - val_loss: 0.9297\nEpoch 10/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9629 - val_loss: 0.9287\n0.6180555555555556\nEpoch 1/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.9464 - val_loss: 0.9495\nEpoch 2/10\n135/135 [==============================] - 2s 12ms/step - loss: 0.9444 - val_loss: 0.9483\nEpoch 3/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.9443 - val_loss: 0.9474\nEpoch 4/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.9420 - val_loss: 0.9467\nEpoch 5/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.9408 - val_loss: 0.9457\nEpoch 6/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.9401 - val_loss: 0.9453\nEpoch 7/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.9390 - val_loss: 0.9448\nEpoch 8/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.9383 - val_loss: 0.9443\nEpoch 9/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.9379 - val_loss: 0.9436\nEpoch 10/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.9369 - val_loss: 0.9429\n0.7083333333333334\nEpoch 1/10\n168/168 [==============================] - 2s 10ms/step - loss: 0.9357 - val_loss: 0.9606\nEpoch 2/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9352 - val_loss: 0.9600\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9343 - val_loss: 0.9607\nEpoch 4/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9334 - val_loss: 0.9617\nEpoch 5/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9329 - val_loss: 0.9601\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9319 - val_loss: 0.9606\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9312 - val_loss: 0.9604\nEpoch 8/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.9307 - val_loss: 0.9595\nEpoch 9/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.9303 - val_loss: 0.9598\nEpoch 10/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.9296 - val_loss: 0.9607\n0.6388888888888888\nEpoch 1/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9348 - val_loss: 0.9345\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9340 - val_loss: 0.9346\nEpoch 3/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9333 - val_loss: 0.9344\nEpoch 4/10\n202/202 [==============================] - 2s 11ms/step - loss: 0.9329 - val_loss: 0.9341\nEpoch 5/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9328 - val_loss: 0.9338\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9323 - val_loss: 0.9347\nEpoch 7/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9317 - val_loss: 0.9350\nEpoch 8/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.9315 - val_loss: 0.9345\nEpoch 9/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.9310 - val_loss: 0.9339\nEpoch 10/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.9305 - val_loss: 0.9344\n0.5833333333333334\nEpoch 1/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.9304 - val_loss: 0.9456\nEpoch 2/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.9299 - val_loss: 0.9448\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9288 - val_loss: 0.9454\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9283 - val_loss: 0.9456\nEpoch 5/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9291 - val_loss: 0.9427\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9276 - val_loss: 0.9436\nEpoch 7/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9267 - val_loss: 0.9414\nEpoch 8/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9263 - val_loss: 0.9405\nEpoch 9/10\n236/236 [==============================] - 2s 11ms/step - loss: 0.9255 - val_loss: 0.9405\nEpoch 10/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.9249 - val_loss: 0.9404\n0.6736111111111112\nEpoch 1/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.9296 - val_loss: 0.9386\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.9285 - val_loss: 0.9372\nEpoch 3/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.9267 - val_loss: 0.9354\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.9257 - val_loss: 0.9334\nEpoch 5/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.9228 - val_loss: 0.9319\nEpoch 6/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.9209 - val_loss: 0.9311\nEpoch 7/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.9177 - val_loss: 0.9297\nEpoch 8/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.9152 - val_loss: 0.9254\nEpoch 9/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.9117 - val_loss: 0.9193\nEpoch 10/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.9076 - val_loss: 0.9187\n0.6805555555555556\nEpoch 1/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.9017 - val_loss: 0.9363\nEpoch 2/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8945 - val_loss: 0.9327\nEpoch 3/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8876 - val_loss: 0.9269\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8788 - val_loss: 0.9145\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8697 - val_loss: 0.9042\nEpoch 6/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8624 - val_loss: 0.8991\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8567 - val_loss: 0.8925\nEpoch 8/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8520 - val_loss: 0.8900\nEpoch 9/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.8475 - val_loss: 0.8978\nEpoch 10/10\n303/303 [==============================] - 3s 11ms/step - loss: 0.8462 - val_loss: 0.8869\n0.6666666666666666\nEpoch 1/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8443 - val_loss: 0.8904\nEpoch 2/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8420 - val_loss: 0.8940\nEpoch 3/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8417 - val_loss: 0.8973\nEpoch 4/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8404 - val_loss: 0.8880\nEpoch 5/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8390 - val_loss: 0.8951\nEpoch 6/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8394 - val_loss: 0.8989\nEpoch 7/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8389 - val_loss: 0.8864\nEpoch 8/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8393 - val_loss: 0.8866\nEpoch 9/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.8390 - val_loss: 0.8862\nEpoch 10/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.8372 - val_loss: 0.8863\n0.6666666666666666\nEpoch 1/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.8454 - val_loss: 0.8674\nEpoch 2/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8442 - val_loss: 0.8646\nEpoch 3/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8451 - val_loss: 0.8609\nEpoch 4/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8447 - val_loss: 0.8610\nEpoch 5/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8447 - val_loss: 0.8616\nEpoch 6/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8434 - val_loss: 0.8595\nEpoch 7/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8432 - val_loss: 0.8594\nEpoch 8/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8423 - val_loss: 0.8641\nEpoch 9/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.8445 - val_loss: 0.8609\nEpoch 10/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.8442 - val_loss: 0.8591\n0.75\nEpoch 1/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8444 - val_loss: 0.8451\nEpoch 2/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.8443 - val_loss: 0.8449\nEpoch 3/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.8447 - val_loss: 0.8490\nEpoch 4/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8432 - val_loss: 0.8442\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8423 - val_loss: 0.8443\nEpoch 6/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8424 - val_loss: 0.8480\nEpoch 7/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8435 - val_loss: 0.8481\nEpoch 8/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.8441 - val_loss: 0.8439\nEpoch 9/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8429 - val_loss: 0.8454\nEpoch 10/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.8425 - val_loss: 0.8456\n0.7291666666666665\nEpoch 1/10\n34/34 [==============================] - 2s 19ms/step - loss: 1.3062 - val_loss: 1.1983\nEpoch 2/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1397 - val_loss: 1.0808\nEpoch 3/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.0419 - val_loss: 0.9903\nEpoch 4/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.9626 - val_loss: 0.9312\nEpoch 5/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.9076 - val_loss: 0.8877\nEpoch 6/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.8740 - val_loss: 0.8615\nEpoch 7/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8519 - val_loss: 0.8458\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8383 - val_loss: 0.8341\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8283 - val_loss: 0.8255\nEpoch 10/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.8203 - val_loss: 0.8186\n0.7847222222222222\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8385 - val_loss: 0.8953\nEpoch 2/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.8288 - val_loss: 0.8865\nEpoch 3/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8207 - val_loss: 0.8790\nEpoch 4/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8138 - val_loss: 0.8731\nEpoch 5/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8089 - val_loss: 0.8675\nEpoch 6/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.8037 - val_loss: 0.8628\nEpoch 7/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.7991 - val_loss: 0.8581\nEpoch 8/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.7951 - val_loss: 0.8539\nEpoch 9/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.7919 - val_loss: 0.8497\nEpoch 10/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.7875 - val_loss: 0.8461\n0.7847222222222222\nEpoch 1/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.8102 - val_loss: 0.7862\nEpoch 2/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8042 - val_loss: 0.7804\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7983 - val_loss: 0.7751\nEpoch 4/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7927 - val_loss: 0.7693\nEpoch 5/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7871 - val_loss: 0.7639\nEpoch 6/10\n101/101 [==============================] - 1s 13ms/step - loss: 0.7816 - val_loss: 0.7583\nEpoch 7/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.7760 - val_loss: 0.7521\nEpoch 8/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7703 - val_loss: 0.7464\nEpoch 9/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7653 - val_loss: 0.7406\nEpoch 10/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.7601 - val_loss: 0.7357\n0.7986111111111112\nEpoch 1/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7502 - val_loss: 0.7970\nEpoch 2/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7433 - val_loss: 0.7897\nEpoch 3/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7373 - val_loss: 0.7824\nEpoch 4/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7319 - val_loss: 0.7763\nEpoch 5/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.7268 - val_loss: 0.7714\nEpoch 6/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7225 - val_loss: 0.7668\nEpoch 7/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7193 - val_loss: 0.7631\nEpoch 8/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7162 - val_loss: 0.7596\nEpoch 9/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.7134 - val_loss: 0.7569\nEpoch 10/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.7103 - val_loss: 0.7548\n0.8472222222222222\nEpoch 1/10\n168/168 [==============================] - 3s 9ms/step - loss: 0.7172 - val_loss: 0.7330\nEpoch 2/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7144 - val_loss: 0.7300\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7124 - val_loss: 0.7264\nEpoch 4/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7095 - val_loss: 0.7235\nEpoch 5/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7071 - val_loss: 0.7215\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7050 - val_loss: 0.7177\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.7019 - val_loss: 0.7160\nEpoch 8/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7002 - val_loss: 0.7125\nEpoch 9/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.6972 - val_loss: 0.7087\nEpoch 10/10\n168/168 [==============================] - 2s 9ms/step - loss: 0.6944 - val_loss: 0.7056\n0.7569444444444444\nEpoch 1/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.6932 - val_loss: 0.6888\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.6894 - val_loss: 0.6844\nEpoch 3/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.6851 - val_loss: 0.6805\nEpoch 4/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.6819 - val_loss: 0.6751\nEpoch 5/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.6782 - val_loss: 0.6709\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.6735 - val_loss: 0.6673\nEpoch 7/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.6709 - val_loss: 0.6623\nEpoch 8/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.6662 - val_loss: 0.6583\nEpoch 9/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.6638 - val_loss: 0.6552\nEpoch 10/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.6595 - val_loss: 0.6516\n0.7777777777777778\nEpoch 1/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.6570 - val_loss: 0.6381\nEpoch 2/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6537 - val_loss: 0.6369\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6522 - val_loss: 0.6350\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6496 - val_loss: 0.6310\nEpoch 5/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.6467 - val_loss: 0.6280\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6443 - val_loss: 0.6314\nEpoch 7/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.6437 - val_loss: 0.6267\nEpoch 8/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6419 - val_loss: 0.6224\nEpoch 9/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6404 - val_loss: 0.6232\nEpoch 10/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.6390 - val_loss: 0.6203\n0.7013888888888888\nEpoch 1/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.6341 - val_loss: 0.6322\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.6327 - val_loss: 0.6334\nEpoch 3/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.6320 - val_loss: 0.6319\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.6301 - val_loss: 0.6335\nEpoch 5/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.6299 - val_loss: 0.6302\nEpoch 6/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.6291 - val_loss: 0.6316\nEpoch 7/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.6285 - val_loss: 0.6296\nEpoch 8/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.6277 - val_loss: 0.6320\nEpoch 9/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.6279 - val_loss: 0.6285\nEpoch 10/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.6265 - val_loss: 0.6276\n0.6736111111111112\nEpoch 1/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6223 - val_loss: 0.6528\nEpoch 2/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6214 - val_loss: 0.6532\nEpoch 3/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6207 - val_loss: 0.6517\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6212 - val_loss: 0.6559\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6206 - val_loss: 0.6522\nEpoch 6/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6210 - val_loss: 0.6538\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6196 - val_loss: 0.6523\nEpoch 8/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6195 - val_loss: 0.6506\nEpoch 9/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.6198 - val_loss: 0.6518\nEpoch 10/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.6192 - val_loss: 0.6505\n0.7083333333333334\nEpoch 1/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6222 - val_loss: 0.6255\nEpoch 2/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6221 - val_loss: 0.6232\nEpoch 3/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6224 - val_loss: 0.6274\nEpoch 4/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.6220 - val_loss: 0.6272\nEpoch 5/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6209 - val_loss: 0.6233\nEpoch 6/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6208 - val_loss: 0.6254\nEpoch 7/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6208 - val_loss: 0.6239\nEpoch 8/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6205 - val_loss: 0.6267\nEpoch 9/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6203 - val_loss: 0.6226\nEpoch 10/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.6194 - val_loss: 0.6208\n0.75\nEpoch 1/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6191 - val_loss: 0.6214\nEpoch 2/10\n370/370 [==============================] - 4s 11ms/step - loss: 0.6186 - val_loss: 0.6186\nEpoch 3/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6180 - val_loss: 0.6182\nEpoch 4/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.6179 - val_loss: 0.6191\nEpoch 5/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6178 - val_loss: 0.6181\nEpoch 6/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6176 - val_loss: 0.6183\nEpoch 7/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.6170 - val_loss: 0.6182\nEpoch 8/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6167 - val_loss: 0.6178\nEpoch 9/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6174 - val_loss: 0.6193\nEpoch 10/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.6166 - val_loss: 0.6179\n0.8125\nEpoch 1/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.6188 - val_loss: 0.6165\nEpoch 2/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6198 - val_loss: 0.6176\nEpoch 3/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6187 - val_loss: 0.6164\nEpoch 4/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6188 - val_loss: 0.6154\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6192 - val_loss: 0.6154\nEpoch 6/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.6201 - val_loss: 0.6212\nEpoch 7/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6190 - val_loss: 0.6159\nEpoch 8/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6189 - val_loss: 0.6213\nEpoch 9/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.6186 - val_loss: 0.6157\nEpoch 10/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.6180 - val_loss: 0.6155\n0.75\nEpoch 1/10\n34/34 [==============================] - 2s 20ms/step - loss: 1.3124 - val_loss: 1.1516\nEpoch 2/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.0768 - val_loss: 0.9920\nEpoch 3/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9530 - val_loss: 0.8887\nEpoch 4/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.8679 - val_loss: 0.8128\nEpoch 5/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8042 - val_loss: 0.7532\nEpoch 6/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.7533 - val_loss: 0.7067\nEpoch 7/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.7125 - val_loss: 0.6679\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.6791 - val_loss: 0.6357\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.6506 - val_loss: 0.6085\nEpoch 10/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.6264 - val_loss: 0.5845\n0.9027777777777778\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5858 - val_loss: 0.5392\nEpoch 2/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5526 - val_loss: 0.5085\nEpoch 3/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.5268 - val_loss: 0.4844\nEpoch 4/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5065 - val_loss: 0.4643\nEpoch 5/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.4904 - val_loss: 0.4489\nEpoch 6/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.4769 - val_loss: 0.4355\nEpoch 7/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.4658 - val_loss: 0.4243\nEpoch 8/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.4564 - val_loss: 0.4148\nEpoch 9/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.4485 - val_loss: 0.4067\nEpoch 10/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.4419 - val_loss: 0.3993\n0.8958333333333334\nEpoch 1/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.4200 - val_loss: 0.4087\nEpoch 2/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.4124 - val_loss: 0.4016\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.4063 - val_loss: 0.3958\nEpoch 4/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.4012 - val_loss: 0.3907\nEpoch 5/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3969 - val_loss: 0.3866\nEpoch 6/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3934 - val_loss: 0.3829\nEpoch 7/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3902 - val_loss: 0.3798\nEpoch 8/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3876 - val_loss: 0.3771\nEpoch 9/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3853 - val_loss: 0.3747\nEpoch 10/10\n101/101 [==============================] - 1s 12ms/step - loss: 0.3832 - val_loss: 0.3725\n0.9027777777777778\nEpoch 1/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3793 - val_loss: 0.4986\nEpoch 2/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3748 - val_loss: 0.4912\nEpoch 3/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3703 - val_loss: 0.4871\nEpoch 4/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3668 - val_loss: 0.4835\nEpoch 5/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3631 - val_loss: 0.4796\nEpoch 6/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3604 - val_loss: 0.4773\nEpoch 7/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3582 - val_loss: 0.4768\nEpoch 8/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3554 - val_loss: 0.4741\nEpoch 9/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3532 - val_loss: 0.4732\nEpoch 10/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3515 - val_loss: 0.4723\n0.9722222222222222\nEpoch 1/10\n168/168 [==============================] - 2s 10ms/step - loss: 0.3776 - val_loss: 0.4022\nEpoch 2/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3759 - val_loss: 0.4016\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3743 - val_loss: 0.4002\nEpoch 4/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3731 - val_loss: 0.3995\nEpoch 5/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3721 - val_loss: 0.3989\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3708 - val_loss: 0.3981\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3699 - val_loss: 0.3975\nEpoch 8/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.3686 - val_loss: 0.3969\nEpoch 9/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3677 - val_loss: 0.3963\nEpoch 10/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3668 - val_loss: 0.3959\n0.8333333333333334\nEpoch 1/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.3718 - val_loss: 0.3974\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3712 - val_loss: 0.3972\nEpoch 3/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.3697 - val_loss: 0.3958\nEpoch 4/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.3687 - val_loss: 0.3950\nEpoch 5/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3683 - val_loss: 0.3946\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3672 - val_loss: 0.3952\nEpoch 7/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3665 - val_loss: 0.3935\nEpoch 8/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3660 - val_loss: 0.3945\nEpoch 9/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3648 - val_loss: 0.3934\nEpoch 10/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3644 - val_loss: 0.3926\n0.8680555555555556\nEpoch 1/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3708 - val_loss: 0.4417\nEpoch 2/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3699 - val_loss: 0.4373\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3692 - val_loss: 0.4380\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3685 - val_loss: 0.4388\nEpoch 5/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3680 - val_loss: 0.4373\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3671 - val_loss: 0.4355\nEpoch 7/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3661 - val_loss: 0.4378\nEpoch 8/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.3653 - val_loss: 0.4323\nEpoch 9/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3653 - val_loss: 0.4365\nEpoch 10/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.3651 - val_loss: 0.4310\n0.8402777777777778\nEpoch 1/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3584 - val_loss: 0.5108\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3568 - val_loss: 0.5161\nEpoch 3/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.3547 - val_loss: 0.5135\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3558 - val_loss: 0.5112\nEpoch 5/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.3548 - val_loss: 0.5112\nEpoch 6/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3536 - val_loss: 0.5165\nEpoch 7/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3542 - val_loss: 0.5090\nEpoch 8/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3534 - val_loss: 0.5149\nEpoch 9/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3530 - val_loss: 0.5073\nEpoch 10/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3527 - val_loss: 0.5141\n0.8541666666666666\nEpoch 1/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.3600 - val_loss: 0.4608\nEpoch 2/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.3585 - val_loss: 0.4619\nEpoch 3/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3592 - val_loss: 0.4555\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3588 - val_loss: 0.4557\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3578 - val_loss: 0.4600\nEpoch 6/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3576 - val_loss: 0.4570\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3578 - val_loss: 0.4558\nEpoch 8/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3570 - val_loss: 0.4601\nEpoch 9/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3574 - val_loss: 0.4621\nEpoch 10/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3571 - val_loss: 0.4575\n0.8819444444444444\nEpoch 1/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3779 - val_loss: 0.4211\nEpoch 2/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3764 - val_loss: 0.4249\nEpoch 3/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3764 - val_loss: 0.4196\nEpoch 4/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3763 - val_loss: 0.4228\nEpoch 5/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3761 - val_loss: 0.4196\nEpoch 6/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3761 - val_loss: 0.4193\nEpoch 7/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3750 - val_loss: 0.4243\nEpoch 8/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3767 - val_loss: 0.4199\nEpoch 9/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3748 - val_loss: 0.4197\nEpoch 10/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3758 - val_loss: 0.4204\n0.8958333333333334\nEpoch 1/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3875 - val_loss: 0.4057\nEpoch 2/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3873 - val_loss: 0.4058\nEpoch 3/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.3875 - val_loss: 0.4083\nEpoch 4/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.3873 - val_loss: 0.4056\nEpoch 5/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3870 - val_loss: 0.4063\nEpoch 6/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.3873 - val_loss: 0.4057\nEpoch 7/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3874 - val_loss: 0.4049\nEpoch 8/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3871 - val_loss: 0.4039\nEpoch 9/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3878 - val_loss: 0.4067\nEpoch 10/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.3862 - val_loss: 0.4037\n0.9513888888888888\nEpoch 1/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.3947 - val_loss: 0.3947\nEpoch 2/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.3940 - val_loss: 0.3954\nEpoch 3/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.3949 - val_loss: 0.3952\nEpoch 4/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3940 - val_loss: 0.3955\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3943 - val_loss: 0.3938\nEpoch 6/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3940 - val_loss: 0.3965\nEpoch 7/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3936 - val_loss: 0.3967\nEpoch 8/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3930 - val_loss: 0.4033\nEpoch 9/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3945 - val_loss: 0.3953\nEpoch 10/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.3947 - val_loss: 0.3933\n0.8333333333333334\nEpoch 1/10\n34/34 [==============================] - 2s 20ms/step - loss: 1.2745 - val_loss: 1.1621\nEpoch 2/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.0842 - val_loss: 1.0244\nEpoch 3/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.9674 - val_loss: 0.9352\nEpoch 4/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.8872 - val_loss: 0.8688\nEpoch 5/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.8264 - val_loss: 0.8177\nEpoch 6/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.7787 - val_loss: 0.7768\nEpoch 7/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.7399 - val_loss: 0.7445\nEpoch 8/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.7084 - val_loss: 0.7163\nEpoch 9/10\n34/34 [==============================] - 0s 12ms/step - loss: 0.6817 - val_loss: 0.6929\nEpoch 10/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.6588 - val_loss: 0.6734\n0.9236111111111112\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.6529 - val_loss: 0.6392\nEpoch 2/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.6255 - val_loss: 0.6154\nEpoch 3/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.6039 - val_loss: 0.5971\nEpoch 4/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.5869 - val_loss: 0.5818\nEpoch 5/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5730 - val_loss: 0.5694\nEpoch 6/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.6132 - val_loss: 0.5597\nEpoch 7/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5518 - val_loss: 0.5511\nEpoch 8/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5437 - val_loss: 0.5436\nEpoch 9/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5366 - val_loss: 0.5376\nEpoch 10/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.5307 - val_loss: 0.5322\n0.9097222222222222\nEpoch 1/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5302 - val_loss: 0.5845\nEpoch 2/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5241 - val_loss: 0.5806\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5190 - val_loss: 0.5774\nEpoch 4/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5147 - val_loss: 0.5748\nEpoch 5/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5110 - val_loss: 0.5726\nEpoch 6/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5078 - val_loss: 0.5708\nEpoch 7/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5050 - val_loss: 0.5693\nEpoch 8/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.5026 - val_loss: 0.5680\nEpoch 9/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.5005 - val_loss: 0.5669\nEpoch 10/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.4986 - val_loss: 0.5661\n0.9097222222222222\nEpoch 1/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.5082 - val_loss: 0.5364\nEpoch 2/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.5066 - val_loss: 0.5352\nEpoch 3/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.5052 - val_loss: 0.5341\nEpoch 4/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.5040 - val_loss: 0.5333\nEpoch 5/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.5028 - val_loss: 0.5325\nEpoch 6/10\n135/135 [==============================] - 1s 11ms/step - loss: 0.5019 - val_loss: 0.5318\nEpoch 7/10\n135/135 [==============================] - 1s 11ms/step - loss: 0.5010 - val_loss: 0.5313\nEpoch 8/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.5002 - val_loss: 0.5308\nEpoch 9/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.4995 - val_loss: 0.5304\nEpoch 10/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.4989 - val_loss: 0.5300\n0.8958333333333334\nEpoch 1/10\n168/168 [==============================] - 2s 9ms/step - loss: 0.5163 - val_loss: 0.4650\nEpoch 2/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5158 - val_loss: 0.4650\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5154 - val_loss: 0.4651\nEpoch 4/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5150 - val_loss: 0.4650\nEpoch 5/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5147 - val_loss: 0.4652\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5144 - val_loss: 0.4653\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5141 - val_loss: 0.4653\nEpoch 8/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5140 - val_loss: 0.4652\nEpoch 9/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5137 - val_loss: 0.4654\nEpoch 10/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.5136 - val_loss: 0.4656\n0.8263888888888888\nEpoch 1/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4997 - val_loss: 0.4479\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4995 - val_loss: 0.4476\nEpoch 3/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.4994 - val_loss: 0.4476\nEpoch 4/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4993 - val_loss: 0.4473\nEpoch 5/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.4992 - val_loss: 0.4473\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4991 - val_loss: 0.4474\nEpoch 7/10\n202/202 [==============================] - 2s 11ms/step - loss: 0.4991 - val_loss: 0.4474\nEpoch 8/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4990 - val_loss: 0.4472\nEpoch 9/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4990 - val_loss: 0.4473\nEpoch 10/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.4989 - val_loss: 0.4474\n0.8680555555555556\nEpoch 1/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5039 - val_loss: 0.4709\nEpoch 2/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5038 - val_loss: 0.4710\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5037 - val_loss: 0.4708\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5038 - val_loss: 0.4707\nEpoch 5/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5037 - val_loss: 0.4707\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5036 - val_loss: 0.4705\nEpoch 7/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5038 - val_loss: 0.4709\nEpoch 8/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5035 - val_loss: 0.4707\nEpoch 9/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5033 - val_loss: 0.4705\nEpoch 10/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.5032 - val_loss: 0.4703\n0.8819444444444444\nEpoch 1/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4782 - val_loss: 0.5368\nEpoch 2/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4778 - val_loss: 0.5369\nEpoch 3/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4776 - val_loss: 0.5368\nEpoch 4/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4773 - val_loss: 0.5366\nEpoch 5/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.4769 - val_loss: 0.5362\nEpoch 6/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4782 - val_loss: 0.5369\nEpoch 7/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4772 - val_loss: 0.5368\nEpoch 8/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4766 - val_loss: 0.5361\nEpoch 9/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4756 - val_loss: 0.5347\nEpoch 10/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.4745 - val_loss: 0.5335\n0.9027777777777778\nEpoch 1/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4795 - val_loss: 0.5016\nEpoch 2/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4774 - val_loss: 0.4984\nEpoch 3/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.4747 - val_loss: 0.4947\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4708 - val_loss: 0.4900\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4663 - val_loss: 0.4839\nEpoch 6/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4623 - val_loss: 0.4787\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4578 - val_loss: 0.4744\nEpoch 8/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4543 - val_loss: 0.4693\nEpoch 9/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4502 - val_loss: 0.4652\nEpoch 10/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.4466 - val_loss: 0.4619\n0.8888888888888888\nEpoch 1/10\n336/336 [==============================] - 3s 7ms/step - loss: 0.4518 - val_loss: 0.4471\nEpoch 2/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.4493 - val_loss: 0.4433\nEpoch 3/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4462 - val_loss: 0.4409\nEpoch 4/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4447 - val_loss: 0.4403\nEpoch 5/10\n336/336 [==============================] - 3s 9ms/step - loss: 0.4430 - val_loss: 0.4374\nEpoch 6/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4417 - val_loss: 0.4339\nEpoch 7/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4408 - val_loss: 0.4323\nEpoch 8/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4396 - val_loss: 0.4323\nEpoch 9/10\n336/336 [==============================] - 3s 7ms/step - loss: 0.4392 - val_loss: 0.4316\nEpoch 10/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.4385 - val_loss: 0.4314\n0.8958333333333334\nEpoch 1/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4388 - val_loss: 0.4100\nEpoch 2/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4380 - val_loss: 0.4069\nEpoch 3/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4383 - val_loss: 0.4053\nEpoch 4/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4371 - val_loss: 0.4065\nEpoch 5/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4358 - val_loss: 0.4035\nEpoch 6/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4377 - val_loss: 0.4036\nEpoch 7/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.4365 - val_loss: 0.4095\nEpoch 8/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4370 - val_loss: 0.4023\nEpoch 9/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4370 - val_loss: 0.4032\nEpoch 10/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.4364 - val_loss: 0.4023\n0.9166666666666666\nEpoch 1/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4318 - val_loss: 0.4039\nEpoch 2/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4317 - val_loss: 0.3977\nEpoch 3/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4323 - val_loss: 0.3978\nEpoch 4/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.4318 - val_loss: 0.3976\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4323 - val_loss: 0.3984\nEpoch 6/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4314 - val_loss: 0.3973\nEpoch 7/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4315 - val_loss: 0.3991\nEpoch 8/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4315 - val_loss: 0.3970\nEpoch 9/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4313 - val_loss: 0.3995\nEpoch 10/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.4311 - val_loss: 0.3972\n0.8819444444444444\nEpoch 1/10\n34/34 [==============================] - 2s 21ms/step - loss: 1.2705 - val_loss: 1.1480\nEpoch 2/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.0616 - val_loss: 0.9892\nEpoch 3/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9067 - val_loss: 0.8111\nEpoch 4/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.6579 - val_loss: 0.4685\nEpoch 5/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.4109 - val_loss: 0.3874\nEpoch 6/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.3866 - val_loss: 0.3870\nEpoch 7/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.3842 - val_loss: 0.3863\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.3859 - val_loss: 0.3856\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.3789 - val_loss: 0.3852\nEpoch 10/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.3781 - val_loss: 0.3852\n0.9444444444444444\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.3938 - val_loss: 0.3316\nEpoch 2/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.3891 - val_loss: 0.3292\nEpoch 3/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.3877 - val_loss: 0.3315\nEpoch 4/10\n68/68 [==============================] - 1s 13ms/step - loss: 0.3857 - val_loss: 0.3280\nEpoch 5/10\n68/68 [==============================] - 1s 11ms/step - loss: 0.3837 - val_loss: 0.3255\nEpoch 6/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.3831 - val_loss: 0.3265\nEpoch 7/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.3829 - val_loss: 0.3236\nEpoch 8/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.3808 - val_loss: 0.3235\nEpoch 9/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.3810 - val_loss: 0.3223\nEpoch 10/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.3798 - val_loss: 0.3245\n0.9027777777777778\nEpoch 1/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3732 - val_loss: 0.4410\nEpoch 2/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3722 - val_loss: 0.4405\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3720 - val_loss: 0.4393\nEpoch 4/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3714 - val_loss: 0.4385\nEpoch 5/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3709 - val_loss: 0.4414\nEpoch 6/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3694 - val_loss: 0.4425\nEpoch 7/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3692 - val_loss: 0.4373\nEpoch 8/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3689 - val_loss: 0.4346\nEpoch 9/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.3689 - val_loss: 0.4391\nEpoch 10/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.3678 - val_loss: 0.4333\n0.8680555555555556\nEpoch 1/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3938 - val_loss: 0.4144\nEpoch 2/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3927 - val_loss: 0.4141\nEpoch 3/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3924 - val_loss: 0.4132\nEpoch 4/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3911 - val_loss: 0.4117\nEpoch 5/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3903 - val_loss: 0.4099\nEpoch 6/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3899 - val_loss: 0.4094\nEpoch 7/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3899 - val_loss: 0.4090\nEpoch 8/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3888 - val_loss: 0.4082\nEpoch 9/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.3875 - val_loss: 0.4076\nEpoch 10/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.3877 - val_loss: 0.4063\n0.9375\nEpoch 1/10\n168/168 [==============================] - 2s 10ms/step - loss: 0.4014 - val_loss: 0.3638\nEpoch 2/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.4001 - val_loss: 0.3645\nEpoch 3/10\n168/168 [==============================] - 2s 9ms/step - loss: 0.3991 - val_loss: 0.3635\nEpoch 4/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.3983 - val_loss: 0.3614\nEpoch 5/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3961 - val_loss: 0.3609\nEpoch 6/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.3949 - val_loss: 0.3572\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3942 - val_loss: 0.3564\nEpoch 8/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3922 - val_loss: 0.3568\nEpoch 9/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3901 - val_loss: 0.3522\nEpoch 10/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.3873 - val_loss: 0.3500\n0.8958333333333334\nEpoch 1/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.3788 - val_loss: 0.3914\nEpoch 2/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3772 - val_loss: 0.3936\nEpoch 3/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3735 - val_loss: 0.3842\nEpoch 4/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3731 - val_loss: 0.3806\nEpoch 5/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.3659 - val_loss: 0.3772\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3637 - val_loss: 0.3738\nEpoch 7/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3608 - val_loss: 0.3709\nEpoch 8/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3587 - val_loss: 0.3678\nEpoch 9/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3535 - val_loss: 0.3702\nEpoch 10/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.3528 - val_loss: 0.3655\n0.9583333333333334\nEpoch 1/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.3502 - val_loss: 0.4323\nEpoch 2/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.3492 - val_loss: 0.4068\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3471 - val_loss: 0.4038\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3460 - val_loss: 0.4021\nEpoch 5/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3476 - val_loss: 0.4057\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3441 - val_loss: 0.4127\nEpoch 7/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3416 - val_loss: 0.4018\nEpoch 8/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3437 - val_loss: 0.4017\nEpoch 9/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.3411 - val_loss: 0.4041\nEpoch 10/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.3425 - val_loss: 0.4369\n0.9097222222222222\nEpoch 1/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3444 - val_loss: 0.4479\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3433 - val_loss: 0.4582\nEpoch 3/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.3424 - val_loss: 0.4500\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.3424 - val_loss: 0.4638\nEpoch 5/10\n269/269 [==============================] - 3s 11ms/step - loss: 0.3401 - val_loss: 0.4432\nEpoch 6/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.3461 - val_loss: 0.4481\nEpoch 7/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.3433 - val_loss: 0.4502\nEpoch 8/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.3457 - val_loss: 0.4389\nEpoch 9/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.3453 - val_loss: 0.4388\nEpoch 10/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.3445 - val_loss: 0.4427\n0.8958333333333334\nEpoch 1/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.3465 - val_loss: 0.4302\nEpoch 2/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3486 - val_loss: 0.4234\nEpoch 3/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.3469 - val_loss: 0.4248\nEpoch 4/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3478 - val_loss: 0.4241\nEpoch 5/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3477 - val_loss: 0.4258\nEpoch 6/10\n303/303 [==============================] - 3s 10ms/step - loss: 0.3479 - val_loss: 0.4302\nEpoch 7/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3479 - val_loss: 0.4283\nEpoch 8/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3476 - val_loss: 0.4240\nEpoch 9/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3502 - val_loss: 0.4262\nEpoch 10/10\n303/303 [==============================] - 3s 9ms/step - loss: 0.3478 - val_loss: 0.4257\n0.9097222222222222\nEpoch 1/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3606 - val_loss: 0.4277\nEpoch 2/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3604 - val_loss: 0.4226\nEpoch 3/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3620 - val_loss: 0.4333\nEpoch 4/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3607 - val_loss: 0.4268\nEpoch 5/10\n336/336 [==============================] - 3s 7ms/step - loss: 0.3608 - val_loss: 0.4308\nEpoch 6/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3605 - val_loss: 0.4290\nEpoch 7/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3597 - val_loss: 0.4268\nEpoch 8/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3639 - val_loss: 0.4311\nEpoch 9/10\n336/336 [==============================] - 3s 8ms/step - loss: 0.3628 - val_loss: 0.4219\nEpoch 10/10\n336/336 [==============================] - 2s 7ms/step - loss: 0.3600 - val_loss: 0.4283\n0.8402777777777778\nEpoch 1/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3726 - val_loss: 0.3883\nEpoch 2/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3763 - val_loss: 0.3849\nEpoch 3/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3751 - val_loss: 0.3860\nEpoch 4/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3767 - val_loss: 0.3849\nEpoch 5/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3723 - val_loss: 0.3845\nEpoch 6/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3732 - val_loss: 0.3905\nEpoch 7/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3749 - val_loss: 0.3850\nEpoch 8/10\n370/370 [==============================] - 4s 10ms/step - loss: 0.3723 - val_loss: 0.3848\nEpoch 9/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3725 - val_loss: 0.3991\nEpoch 10/10\n370/370 [==============================] - 3s 9ms/step - loss: 0.3743 - val_loss: 0.3864\n0.9444444444444444\nEpoch 1/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.3731 - val_loss: 0.3825\nEpoch 2/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3723 - val_loss: 0.3807\nEpoch 3/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3727 - val_loss: 0.3807\nEpoch 4/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3740 - val_loss: 0.3896\nEpoch 5/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3727 - val_loss: 0.3804\nEpoch 6/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3716 - val_loss: 0.3800\nEpoch 7/10\n404/404 [==============================] - 4s 10ms/step - loss: 0.3744 - val_loss: 0.3807\nEpoch 8/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3728 - val_loss: 0.3833\nEpoch 9/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3734 - val_loss: 0.3832\nEpoch 10/10\n404/404 [==============================] - 4s 9ms/step - loss: 0.3714 - val_loss: 0.3811\n0.8680555555555556\nEpoch 1/10\n34/34 [==============================] - 3s 22ms/step - loss: 1.3243 - val_loss: 1.2584\nEpoch 2/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.2165 - val_loss: 1.1799\nEpoch 3/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.1486 - val_loss: 1.1115\nEpoch 4/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.0991 - val_loss: 1.0574\nEpoch 5/10\n34/34 [==============================] - 0s 11ms/step - loss: 1.0625 - val_loss: 1.0388\nEpoch 6/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.0426 - val_loss: 1.0256\nEpoch 7/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.0254 - val_loss: 1.0182\nEpoch 8/10\n34/34 [==============================] - 0s 10ms/step - loss: 1.0127 - val_loss: 1.0113\nEpoch 9/10\n34/34 [==============================] - 0s 10ms/step - loss: 0.9979 - val_loss: 1.0030\nEpoch 10/10\n34/34 [==============================] - 0s 11ms/step - loss: 0.9868 - val_loss: 0.9984\n0.6527777777777778\nEpoch 1/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9991 - val_loss: 1.0225\nEpoch 2/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9841 - val_loss: 1.0011\nEpoch 3/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9705 - val_loss: 0.9915\nEpoch 4/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.9630 - val_loss: 0.9831\nEpoch 5/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9476 - val_loss: 0.9736\nEpoch 6/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9377 - val_loss: 0.9689\nEpoch 7/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9296 - val_loss: 0.9567\nEpoch 8/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9212 - val_loss: 0.9523\nEpoch 9/10\n68/68 [==============================] - 1s 9ms/step - loss: 0.9138 - val_loss: 0.9410\nEpoch 10/10\n68/68 [==============================] - 1s 10ms/step - loss: 0.9061 - val_loss: 0.9343\n0.6388888888888888\nEpoch 1/10\n101/101 [==============================] - 1s 11ms/step - loss: 0.9127 - val_loss: 0.8523\nEpoch 2/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.9011 - val_loss: 0.8450\nEpoch 3/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8928 - val_loss: 0.8393\nEpoch 4/10\n101/101 [==============================] - 1s 12ms/step - loss: 0.8843 - val_loss: 0.8378\nEpoch 5/10\n101/101 [==============================] - 1s 10ms/step - loss: 0.8795 - val_loss: 0.8290\nEpoch 6/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8724 - val_loss: 0.8236\nEpoch 7/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8665 - val_loss: 0.8213\nEpoch 8/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8617 - val_loss: 0.8183\nEpoch 9/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8564 - val_loss: 0.8116\nEpoch 10/10\n101/101 [==============================] - 1s 9ms/step - loss: 0.8513 - val_loss: 0.8101\n0.6944444444444444\nEpoch 1/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.8349 - val_loss: 0.8406\nEpoch 2/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.8299 - val_loss: 0.8376\nEpoch 3/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.8258 - val_loss: 0.8353\nEpoch 4/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.8218 - val_loss: 0.8330\nEpoch 5/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.8188 - val_loss: 0.8308\nEpoch 6/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.8164 - val_loss: 0.8289\nEpoch 7/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.8122 - val_loss: 0.8275\nEpoch 8/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.8098 - val_loss: 0.8263\nEpoch 9/10\n135/135 [==============================] - 1s 9ms/step - loss: 0.8070 - val_loss: 0.8251\nEpoch 10/10\n135/135 [==============================] - 1s 10ms/step - loss: 0.8044 - val_loss: 0.8238\n0.8541666666666666\nEpoch 1/10\n168/168 [==============================] - 2s 9ms/step - loss: 0.8106 - val_loss: 0.7939\nEpoch 2/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.8092 - val_loss: 0.7945\nEpoch 3/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.8074 - val_loss: 0.7937\nEpoch 4/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.8054 - val_loss: 0.7959\nEpoch 5/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.8058 - val_loss: 0.7936\nEpoch 6/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.8021 - val_loss: 0.7948\nEpoch 7/10\n168/168 [==============================] - 1s 7ms/step - loss: 0.8011 - val_loss: 0.7913\nEpoch 8/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.8015 - val_loss: 0.7903\nEpoch 9/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7989 - val_loss: 0.7951\nEpoch 10/10\n168/168 [==============================] - 1s 8ms/step - loss: 0.7986 - val_loss: 0.7950\n0.7291666666666665\nEpoch 1/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.7922 - val_loss: 0.8007\nEpoch 2/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.7917 - val_loss: 0.7990\nEpoch 3/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.7900 - val_loss: 0.7956\nEpoch 4/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.7895 - val_loss: 0.7975\nEpoch 5/10\n202/202 [==============================] - 2s 10ms/step - loss: 0.7901 - val_loss: 0.7962\nEpoch 6/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7878 - val_loss: 0.7966\nEpoch 7/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7879 - val_loss: 0.7997\nEpoch 8/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7871 - val_loss: 0.7987\nEpoch 9/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7871 - val_loss: 0.7968\nEpoch 10/10\n202/202 [==============================] - 2s 9ms/step - loss: 0.7872 - val_loss: 0.7973\n0.7291666666666665\nEpoch 1/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.7933 - val_loss: 0.7947\nEpoch 2/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7916 - val_loss: 0.7880\nEpoch 3/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7922 - val_loss: 0.7883\nEpoch 4/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7912 - val_loss: 0.7889\nEpoch 5/10\n236/236 [==============================] - 2s 11ms/step - loss: 0.7919 - val_loss: 0.7928\nEpoch 6/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7913 - val_loss: 0.7879\nEpoch 7/10\n236/236 [==============================] - 2s 10ms/step - loss: 0.7921 - val_loss: 0.7906\nEpoch 8/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7911 - val_loss: 0.7893\nEpoch 9/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7901 - val_loss: 0.7916\nEpoch 10/10\n236/236 [==============================] - 2s 9ms/step - loss: 0.7922 - val_loss: 0.7883\n0.7291666666666665\nEpoch 1/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.7841 - val_loss: 0.7997\nEpoch 2/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7841 - val_loss: 0.7988\nEpoch 3/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7841 - val_loss: 0.7985\nEpoch 4/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7833 - val_loss: 0.7995\nEpoch 5/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.7839 - val_loss: 0.7987\nEpoch 6/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7839 - val_loss: 0.7997\nEpoch 7/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7841 - val_loss: 0.7988\nEpoch 8/10\n269/269 [==============================] - 3s 10ms/step - loss: 0.7831 - val_loss: 0.8031\nEpoch 9/10\n269/269 [==============================] - 3s 9ms/step - loss: 0.7838 - val_loss: 0.7988\nEpoch 10/10\n269/269 [==============================] - 2s 9ms/step - loss: 0.7840 - val_loss: 0.7990\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Predictions**","metadata":{}},{"cell_type":"markdown","source":"**Example of prediction**","metadata":{}},{"cell_type":"markdown","source":"**Evaluation of the predictions**","metadata":{}},{"cell_type":"markdown","source":"# Recursive Forecust","metadata":{}},{"cell_type":"markdown","source":"we will use recursive forecast to predict more than one step in the future","metadata":{}},{"cell_type":"code","source":"def recursive_forecast(model, data, window_size, horizon):\n    forecast = []\n    for i in range(horizon):\n        # Use the last window_size elements of data as input\n        input_data = data[-window_size:, 0]\n        # Reshape the input data to the shape expected by the model\n        input_data = input_data.reshape((1, window_size, 1))\n        # Get the next forecast\n        next_forecast = model.predict(input_data)\n        # Append the forecast to the data\n        arg_max=np.argmax(next_forecast[0],axis=0)\n        data = np.append(data, arg_max)\n        data=data.reshape(data.shape[0],1)\n        forecast.append(arg_max)\n    return forecast","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the recursive function to make a forecast for 2 hours in the future\nsample_predict=recursive_forecast(estimator, data, 24,2)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T17:18:01.060180Z","iopub.status.idle":"2023-01-16T17:18:01.061068Z","shell.execute_reply.started":"2023-01-16T17:18:01.060800Z","shell.execute_reply":"2023-01-16T17:18:01.060824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_predict","metadata":{"execution":{"iopub.status.busy":"2023-01-16T17:18:01.062446Z","iopub.status.idle":"2023-01-16T17:18:01.063273Z","shell.execute_reply.started":"2023-01-16T17:18:01.063027Z","shell.execute_reply":"2023-01-16T17:18:01.063050Z"},"trusted":true},"execution_count":null,"outputs":[]}]}